# Облачные  и высокопроизводительные вычисления
---
### Salt And Pepper
- Лабораторная написана на языке Python 3 с использованием библиотеки `pycuda`
    - CUDA-ядро написано на С++ и обернуто в python-функцию
- Для получения массива чисел, характеризующих цвет пикселя использовалась библиотека `Pillow`  
- Каждый элемент выходного изображения вычислялся (на GPU) отдельной нитью (потоком)
- Для ускорения вычислений на GPU внутри каждого блока изображения было реализовано копирование элементов из глобальной памяти в разделяемую, что позволило уменьшить число обращений к глобальной памяти


|Исходное изображение 256x256| Обработанное на CPU | Обработанное на GPU |
|:--------------------------:|:-------------------:|:-------------------:|
| ![](SaltAndPepperImages/256.bmp) | ![](SaltAndPepperImages/cpu256.bmp) | ![](SaltAndPepperImages/gpu256.bmp) |

- Результаты для фильтра 3х3 (усредненные по нескольким запускам)

|   File   | CPU time, ms | GPU time, ms | Speedup |
|:--------:|:------------:|:------------:|:-------:|
| 256.bmp  |      556.000 |        0.351 | 1585.50 |
| 512.bmp  |     2334.820 |        0.509 | 4591.42 |
| 1024.bmp |     9366.697 |        1.511 | 6200.49 |

- Результаты для фильтра 5х5 (усредненные по нескольким запускам)

|   File   | CPU time, ms | GPU time, ms | Speedup |
|:--------:|:------------:|:------------:|:-------:|
| 256.bmp  |     1232.150 |        0.967 | 1274.56 |
| 512.bmp  |     5238.691 |        2.454 | 2135.13 |
| 1024.bmp |    20812.174 |        7.231 | 2878.32 |

- Выводы
    -  Использование GPU в рамках задачи медианной фильтрации дает колоссальный прирост в скорости
---
### Matrix Multiplication
- Лабораторная написана на языке Python 3 с использованием библиотеки `pycuda`
    - CUDA-ядро написано на С++ и обернуто в python-функцию
- Для вычислений на CPU использовалась библиотека `numpy`
    - Не вижу смысла реализовывать `ijk` и ему подобные алгоритмы, потому что они работают заведомо медленнее   
- Каждый элемент выходной матрицы вычислялся (на GPU) отдельной нитью (потоком)
- Для ускорения вычислений на GPU внутри каждого блока матрицы было реализовано копирование элементов из глобальной памяти в разделяемую, что позволило уменьшить число обращений к глобальной памяти в BLOCK_SIZE раз, где BLOCK_SIZE - размер блока GPU 

- Результаты (усредненные по нескольким запускам)

  |Size | CPU time, ms | GPU time, ms | Speedup|
  |:---:|:------------:|:------------:|:------:|
  | 128 |        0.293 |        0.661 |    0.44|
  | 256 |        0.638 |        0.899 |    0.71|
  | 512 |        4.608 |        2.926 |    1.57|
  |1024 |       35.526 |       11.086 |    3.20|
  |2048 |      266.146 |       59.547 |    4.47|
  
- Выводы
    -  При небольших размерах исходных матриц вычисление на GPU происходит медленнее, так помимо самих вычислений происходит передача данных с хоста на девайс, которая и влечет за собой такие результаты
    -  Учитывая полученные результаты (здесь нам интересно ускорение), можно сделать вывод о том, что в рамках задачи перемножения матриц перенос вычислений с CPU на GPU будет целесообразен только для очень больших матриц.
---